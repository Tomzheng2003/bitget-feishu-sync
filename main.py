# main.py - ä¸»ç¨‹åºå…¥å£ (å¤šäº¤æ˜“æ‰€ç‰ˆ: Bitget + Binance)
# äº¤æ˜“æ—¥å¿—è‡ªåŠ¨åŒæ­¥ç³»ç»Ÿ

import os
import json
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv

# å¯¼å…¥åŠŸèƒ½æ¨¡å—
import bitget_client
import binance_client
import feishu_client
import logging
from logging.handlers import TimedRotatingFileHandler

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ==========================
# æ—¥å¿—é…ç½® (Log Rotation)
# ==========================
LOG_DIR = "data/logs"
if not os.path.exists(LOG_DIR):
    try:
        os.makedirs(LOG_DIR)
    except:
        LOG_DIR = "logs"
        if not os.path.exists(LOG_DIR): os.makedirs(LOG_DIR)

log_file = os.path.join(LOG_DIR, "trade.log")

logger = logging.getLogger("TradeSync")
logger.setLevel(logging.INFO)

# 1. æ–‡ä»¶å¤„ç†å™¨
file_handler = TimedRotatingFileHandler(
    log_file, when="midnight", interval=1, backupCount=7, encoding="utf-8"
)
file_handler.suffix = "%Y-%m-%d"
file_formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
file_handler.setFormatter(file_formatter)

# 2. æ§åˆ¶å°å¤„ç†å™¨
console_handler = logging.StreamHandler()
console_formatter = logging.Formatter('[%(levelname)s] %(message)s')
console_handler.setFormatter(console_formatter)

logger.addHandler(file_handler)
logger.addHandler(console_handler)

def log_info(msg): logger.info(msg)
def log_error(msg): logger.error(msg)

# å°†çŠ¶æ€æ–‡ä»¶ç§»å…¥ data ç›®å½•ï¼Œé…åˆ Docker æŒ‚è½½æ•´ä¸ª data ç›®å½•ä½¿ç”¨
STATE_FILE = "data/state.json"
# ç¡®ä¿ data ç›®å½•å­˜åœ¨
if not os.path.exists("data"):
    try:
        os.makedirs("data")
    except:
        pass

try:
    poll_env = os.getenv("POLL_INTERVAL", "10")
    if not poll_env: poll_env = "10"
    POLL_INTERVAL = int(poll_env)
except Exception:
    POLL_INTERVAL = 10

def load_state() -> dict:
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, 'r', encoding='utf-8') as f: return json.load(f)
        except Exception as e:
            print(f"[Core] åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    return {}

def save_state(state: dict):
    try:
        with open(STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=4, ensure_ascii=False)
    except Exception as e:
        print(f"[Core] ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")

def get_unique_id(exchange, pos: dict) -> str:
    """å”¯ä¸€æ ‡è¯†ç¬¦: {Exchange}_{Symbol}_{Side}_{Time}"""
    # 1. å†å²è®°å½•: ä½¿ç”¨è‡ªå¸¦çš„å”¯ä¸€ID (Binance OrderId / TranId)
    if pos.get("id"):
        return f"{exchange}_{pos['symbol']}_{pos.get('holdSide', 'side')}_{pos['id']}"
    
    # 2. Binance æŒä»“: ä½¿ç”¨å›ºå®š IDï¼Œæ–¹ä¾¿å¹³ä»“æ—¶æŸ¥æ‰¾å¹¶åˆå¹¶
    if exchange == "Binance":
         return f"Binance_{pos.get('symbol')}_{pos.get('holdSide')}_HOLDING"
         
    # 3. å¸¸è§„æŒä»“ (Bitget): ä½¿ç”¨ cTime å»é‡
    symbol = pos.get("symbol", "")
    side = pos.get("holdSide", "")
    c_time = pos.get("cTime") or pos.get("ctime") or pos.get("CTime") or "0"
    return f"{exchange}_{symbol}_{side}_{c_time}"

def format_duration(start_ms, end_ms):
    try:
        if not end_ms or not start_ms: return ""
        diff_ms = int(end_ms) - int(start_ms)
        if diff_ms < 0: return "0s"
        seconds = int(diff_ms / 1000)
        if seconds < 60: return f"{seconds}s"
        elif seconds < 3600: return f"{seconds // 60}m {seconds % 60}s"
        elif seconds < 86400: return f"{seconds // 3600}h {(seconds % 3600) // 60}m"
        else: return f"{seconds // 86400}d {(seconds % 86400) // 3600}h"
    except: return ""

# äº¤æ˜“æ‰€é…ç½®åˆ—è¡¨
# äº¤æ˜“æ‰€é…ç½®åˆ—è¡¨
EXCHANGES = [
    {"name": "Bitget", "client": bitget_client},
    # {"name": "Binance", "client": binance_client} # æš‚æ—¶å…³é—­å¸å®‰ï¼Œä¸“æ³¨äº Bitget ç¨³å®šæ€§
]

def sync_tasks():
    state = load_state()
    synced_ids = set(state.get("synced_ids", []))
    feishu_cache = state.get("feishu_cache", {})
    
    # ä¼˜åŒ–: å¦‚æœç¼“å­˜ä¸ºç©º(å…¨æ–°å¯åŠ¨)ï¼Œå…ˆå…¨é‡æ‹‰å–é£ä¹¦è®°å½•ï¼Œé¿å… N+1 æŸ¥è¯¢
    if not feishu_cache:
        try:
            feishu_cache = feishu_client.get_all_records()
            state["feishu_cache"] = feishu_cache
            # ä¸å¿…ç«‹å³ä¿å­˜ï¼Œå‡½æ•°æœ«å°¾ä¼šå­˜
        except Exception as e:
            log_error(f"åˆå§‹åŒ–é£ä¹¦ç¼“å­˜å¤±è´¥: {e}")

    finalized_ids = set(state.get("finalized_ids", []))
    
    print(f"\n[{datetime.now().strftime('%H:%M:%S')}] å¼€å§‹åŒæ­¥ (Interval: {POLL_INTERVAL}s)")

    for ex in EXCHANGES:
        ex_name = ex["name"]
        client = ex["client"]
        
        # --- 1. å½“å‰æŒä»“ ---
        try:
            open_positions = client.get_positions()
        except Exception as e:
            log_error(f"[{ex_name}] è·å–æŒä»“å¤±è´¥: {e}")
            open_positions = []
            
        print(f"[{ex_name}] æŒä»“: {len(open_positions)} ä¸ª")

        for pos in open_positions:
            unique_id = get_unique_id(ex_name, pos)
            
            c_time_ms = int(pos.get("cTime") or 0)
            entry_price = float(pos.get("openPriceAvg") or pos.get("openAvgPrice") or 0)
            leverage = int(pos.get("leverage", 0))
            unrealized_pnl = float(pos.get("unrealizedPL", 0))
            
            # è®¡ç®— ROE
            roe = float(pos.get("roe", 0))
            margin_size = float(pos.get("marginSize", 0))
            if roe == 0 and margin_size > 0:
                 roe = round((unrealized_pnl / margin_size), 4)

            fields = {
                "äº¤æ˜“æ‰€": ex_name,
                "å¼€ä»“æ—¶é—´": c_time_ms, # é£ä¹¦æ—¥æœŸå­—æ®µå»ºè®®ä¼ æ—¶é—´æˆ³
                "å¸ç§": pos.get("symbol", ""),
                "æ–¹å‘": "å¤š" if pos.get("holdSide") == "long" else "ç©º",
                "æ æ†": leverage,
                "å…¥åœºä»·": entry_price,
                "å‡ºåœºä»·": 0,
                "æ”¶ç›Šé¢": unrealized_pnl, 
                "æ”¶ç›Šç‡": roe,
                "çŠ¶æ€": "æŒä»“ä¸­",
                "positionId": unique_id,
                "å¹³ä»“æ—¶é—´": None,
                "æŒä»“æ—¶é—´": format_duration(c_time_ms, int(time.time() * 1000)) + " (ing)"
            }
            
            # Smart Journal Logic
            # Smart Journal Logic
            cached_data = feishu_cache.get(unique_id)
            if not cached_data:
                # Case 1: å…¨æ–°æŒä»“ -> å¿…é¡»åˆ›å»º
                log_info(f"  [{ex_name}] ğŸŸ¢ æ–°å¢æŒä»“: {fields['å¸ç§']}")
                existing_id = feishu_client.find_record(unique_id)
                if existing_id:
                    feishu_client.update_record(existing_id, fields)
                    record_id = existing_id
                else:
                    record_id = feishu_client.create_record(fields)
                
                if record_id:
                    feishu_cache[unique_id] = {
                        "record_id": record_id,
                        "entry_price": entry_price,
                        "leverage": leverage
                    }
                    synced_ids.add(unique_id)
            else:
                # Case 2: å·²å­˜åœ¨çš„æŒä»“ -> æ£€æŸ¥æ˜¯å¦å‘ç”Ÿ"ç»“æ„æ€§å˜æ›´" (DCA)
                last_entry_price = cached_data.get("entry_price", 0)
                last_leverage = cached_data.get("leverage", 0)
                record_id = cached_data.get("record_id")
                
                # Binance ç‰¹æ®Šå¤„ç†ï¼šå› ä¸º ID æ˜¯å›ºå®šçš„ï¼Œé˜²æ­¢é‡å¤åˆ·æ–°ï¼Œå¯ä»¥åŠ ä¸€ç‚¹ä»·æ ¼é˜ˆå€¼
                is_dca_event = abs(entry_price - last_entry_price) > (entry_price * 0.000001) or leverage != last_leverage
                
                if is_dca_event:
                    log_info(f"  [{ex_name}] ğŸŸ¡ ä»“ä½å˜åŠ¨: {fields['å¸ç§']}")
                    if feishu_client.update_record(record_id, fields):
                        feishu_cache[unique_id]["entry_price"] = entry_price
                        feishu_cache[unique_id]["leverage"] = leverage

    # ä¿å­˜ç¼“å­˜çŠ¶æ€ (Open Position loop end)
    
        # --- 2. å†å²è®°å½• ---
        try:
            history_list = client.get_history_positions()
        except Exception as e:
            log_error(f"[{ex_name}] è·å–å†å²ä»“ä½å¤±è´¥: {e}")
            history_list = []
        
        log_info(f"[{ex_name}] å†å²è®°å½•: {len(history_list)} æ¡")
        
        for pos in history_list:
            unique_id = get_unique_id(ex_name, pos)
            if unique_id in finalized_ids: continue
            
            c_time_ms = int(pos.get("ctime") or pos.get("cTime") or 0)
            u_time_ms = int(pos.get("utime") or pos.get("uTime") or 0)
            # 1. æå– PnL (Gross Profit)
            pnl = float(pos.get("pnl", 0))

            # 2. è®¡ç®—æ€»æ‰‹ç»­è´¹ (å¼€ä»“è´¹ + å¹³ä»“è´¹ + èµ„é‡‘è´¹) - é€šå¸¸ä¸ºè´Ÿæ•°
            total_fee = float(pos.get("openFee", 0)) + float(pos.get("closeFee", 0)) + float(pos.get("totalFunding", 0))
            
            # 3. è®¡ç®—å‡€æ”¶ç›Š (Net Profit) = PnL + Total Fee
            # Bitget çš„ netProfit å­—æ®µé€šå¸¸å·²ç»æ˜¯å‡€å€¼ï¼Œä½†ä¸ºäº†ç¡®ä¿ä¸‡æ— ä¸€å¤±ï¼Œæˆ‘ä»¬æ‰‹åŠ¨ç®—
            final_profit = pnl + total_fee

            # === æ ¸å¿ƒé€»è¾‘: å°è¯•å…³è” Holding è®°å½•ä»¥è·å–æ æ†ä¿¡æ¯ ===
            # === æ ¸å¿ƒé€»è¾‘: å°è¯•å…³è” Holding è®°å½•ä»¥è·å–æ æ†ä¿¡æ¯ ===
            cached_data = feishu_cache.get(unique_id, {})
            cached_leverage = cached_data.get("leverage", 0)
            
            # å¦‚æœç¼“å­˜æ²¡æœ‰ï¼Œä¸”æ˜¯ Binance (æœªæ¥å¤‡ç”¨)ï¼Œå°è¯•å»æ‰¾ Holding
            if not cached_leverage and ex_name == "Binance":
                 holding_id = f"Binance_{pos['symbol']}_{pos['holdSide']}_HOLDING"
                 if holding_id in feishu_cache:
                     cached_leverage = feishu_cache[holding_id].get("leverage", 0)

            # ä¸¥æ ¼æ¨¡å¼: å¦‚æœä¸çŸ¥é“æ æ†(cached_leverage == 0)ï¼Œè¯´æ˜è¿™æ˜¯æœºå™¨äººæœªè¿½è¸ªè¿‡çš„å†å²æ•°æ®
            # ä¸ºäº†é˜²æ­¢è¦†ç›–ç”¨æˆ·æ‰‹åŠ¨å¡«å†™çš„æ­£ç¡®æ•°æ®ï¼Œç›´æ¥è·³è¿‡å¤„ç†
            if cached_leverage == 0:
                # log_info(f"[{ex_name}] â­ï¸ è·³è¿‡æœªè¿½è¸ªå†å²: {pos.get('symbol')} (æ— æ æ†ä¿¡æ¯)")
                continue
            
            # è®¡ç®— ROE (ä½¿ç”¨å‡€æ”¶ç›Š)
            
            # è®¡ç®— ROE (ä½¿ç”¨å‡€æ”¶ç›Š)
            roe = 0
            open_val = float(pos.get("openAvgPrice", 0)) * float(pos.get("openTotalPos", 0) or pos.get("size", 0))
            if open_val > 0:
                margin = open_val / cached_leverage
                roe = final_profit / margin

            fields = {
                "äº¤æ˜“æ‰€": ex_name,
                "å¼€ä»“æ—¶é—´": c_time_ms,
                "å¸ç§": pos.get("symbol", ""),
                "æ–¹å‘": "å¤š" if pos.get("holdSide") == "long" else "ç©º",
                "å…¥åœºä»·": float(pos.get("openAvgPrice", 0)),
                "å‡ºåœºä»·": float(pos.get("closeAvgPrice", 0)),
                "æ”¶ç›Šé¢": final_profit, # ç¡®è®¤æ˜¯å‡€æ”¶ç›Š
                "æ”¶ç›Šç‡": roe,
                "æ‰‹ç»­è´¹": total_fee,
                "çŠ¶æ€": "ç›ˆåˆ©" if final_profit > 0 else "äºæŸ",
                "positionId": unique_id, # æœ€ç»ˆ ID
                "å¹³ä»“æ—¶é—´": u_time_ms,
                "æŒä»“æ—¶é—´": format_duration(c_time_ms, u_time_ms),
                "æ æ†": int(cached_leverage)
            }
    
            # === æ ¸å¿ƒé€»è¾‘: å°è¯•å…³è” Holding è®°å½• ===
            record_id = None
            
            # 1. å…ˆæŸ¥ç¼“å­˜é‡Œçš„ History ID (å¸¸è§„)
            cached_data = feishu_cache.get(unique_id, {})
            record_id = cached_data.get("record_id")
            
            # 2. å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä¸”æ˜¯ Binanceï¼Œå°è¯•å»æ‰¾å¯¹åº”çš„ "HOLDING" è®°å½•è¿›è¡Œåˆå¹¶
            if not record_id and ex_name == "Binance":
                holding_id = f"Binance_{pos['symbol']}_{pos['holdSide']}_HOLDING"
                # æŸ¥ç¼“å­˜
                if holding_id in feishu_cache:
                    record_id = feishu_cache[holding_id].get("record_id")
                    log_info(f"  [{ex_name}] ğŸ”— å…³è”æŒä»“è®°å½•: {holding_id} -> {unique_id}")
                    # æ¸…é™¤ Holding ç¼“å­˜ï¼Œå› ä¸ºå®ƒå˜èº«äº†
                    del feishu_cache[holding_id]
                    
                # å¦‚æœç¼“å­˜ä¹Ÿæ²¡ï¼ŒæŸ¥é£ä¹¦ (åŒä¿é™©)
                if not record_id:
                    record_id = feishu_client.find_record(holding_id)
                    if record_id:
                        log_info(f"  [{ex_name}] ğŸ”— å‘ç°è¿œç¨‹æŒä»“: {holding_id}")
    
            # 3. å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼ŒæŒ‰å¸¸è§„ ID æŸ¥ (è¡¥å½•æƒ…å†µ)
            if not record_id: 
                record_id = feishu_client.find_record(unique_id)
            
            if record_id:
                log_info(f"  [{ex_name}] ğŸ”µ è®¢å•å®Œç»“: {fields['å¸ç§']}")
                if feishu_client.update_record(record_id, fields): finalized_ids.add(unique_id)
            else:
                log_info(f"  [{ex_name}] ğŸŸ£ è¡¥å½•å†å²: {fields['å¸ç§']}")
                if feishu_client.create_record(fields):
                    # synced_ids.add(unique_id)
                    finalized_ids.add(unique_id)
            
            # é¢‘ç‡é™åˆ¶ä¿æŠ¤: é£ä¹¦ API åˆ›å»ºè®°å½•é€šå¸¸æœ‰ 5 QPS é™åˆ¶
            # å¦‚æœå¤§é‡è¡¥å½•ï¼Œå¿…é¡»æš‚åœä»¥é˜²è¢«å°ç¦æˆ–å¡æ­»
            time.sleep(0.2)
                    
        # Save
        state["feishu_cache"] = feishu_cache
        state["finalized_ids"] = list(finalized_ids)[-2000:]
        state["synced_ids"] = list(synced_ids)[-3000:]
        state["last_sync_time"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        save_state(state)
    
if __name__ == "__main__":
    log_info(f"å¯åŠ¨åŒäº¤æ˜“æ‰€åŒæ­¥ (Bitget + Binance)")
    log_info(f"è½®è¯¢é—´éš”: {POLL_INTERVAL} ç§’")
    while True:
        try:
            sync_tasks()
            # log_info(f"ç­‰å¾… {POLL_INTERVAL} ç§’...")
            time.sleep(POLL_INTERVAL)
        except KeyboardInterrupt:
            log_info("ç¨‹åºåœæ­¢")
            break
        except Exception as e:
            log_error(f"ä¸»å¾ªç¯å¼‚å¸¸: {e}")
            time.sleep(POLL_INTERVAL)
