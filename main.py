# main.py - ä¸»ç¨‹åºå…¥å£ (æ™ºèƒ½æ—¥å¿—æ¨¡å¼)
# Bitget äº¤æ˜“æ—¥å¿—è‡ªåŠ¨åŒæ­¥ç³»ç»Ÿ

import os
import json
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv

# å¯¼å…¥åŠŸèƒ½æ¨¡å—
import bitget_client
import feishu_client
import logging
from logging.handlers import TimedRotatingFileHandler

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ==========================
# æ—¥å¿—é…ç½® (Log Rotation)
# ==========================
LOG_DIR = "/app/logs"
if not os.path.exists(LOG_DIR):
    try:
        os.makedirs(LOG_DIR)
    except:
        LOG_DIR = "logs" # å¦‚æœåœ¨æœ¬åœ°è¿è¡Œ
        if not os.path.exists(LOG_DIR): os.makedirs(LOG_DIR)

log_file = os.path.join(LOG_DIR, "trade.log")

# åˆ›å»º Logger
logger = logging.getLogger("TradeSync")
logger.setLevel(logging.INFO)

# 1. æ–‡ä»¶å¤„ç†å™¨: æ¯å¤©åˆå¤œè½®è½¬ï¼Œä¿ç•™7å¤©
file_handler = TimedRotatingFileHandler(
    log_file, when="midnight", interval=1, backupCount=7, encoding="utf-8"
)
file_handler.suffix = "%Y-%m-%d" # æ–‡ä»¶åç¼€æ ¼å¼
file_formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
file_handler.setFormatter(file_formatter)

# 2. æ§åˆ¶å°å¤„ç†å™¨: ç”¨äº Docker logs æŸ¥çœ‹
console_handler = logging.StreamHandler()
console_formatter = logging.Formatter('[%(levelname)s] %(message)s')
console_handler.setFormatter(console_formatter)

# æ·»åŠ å¤„ç†å™¨
logger.addHandler(file_handler)
logger.addHandler(console_handler)


def log_info(msg):
    logger.info(msg)

def log_error(msg):
    logger.error(msg)


STATE_FILE = "state.json"
# é»˜è®¤è½®è¯¢é—´éš” 10 ç§’ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–
POLL_INTERVAL = int(os.getenv("POLL_INTERVAL", 10))


def load_state() -> dict:
    """Step 3.1: çŠ¶æ€è¯»å–"""
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"[Core] åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    return {}


def save_state(state: dict):
    """Step 3.2: çŠ¶æ€å†™å…¥"""
    try:
        with open(STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=4, ensure_ascii=False)
    except Exception as e:
        print(f"[Core] ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")


def get_unique_id(pos: dict) -> str:
    """
    ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦
    é€»è¾‘ï¼š{symbol}_{holdSide}_{cTime}
    """
    symbol = pos.get("symbol", "")
    side = pos.get("holdSide", "")
    c_time = pos.get("cTime") or pos.get("ctime") or pos.get("CTime") or "0"
    return f"{symbol}_{side}_{c_time}"


def calculate_roe(pnl, margin_size=0, open_avg=0, total=0, leverage=0):
    """è®¡ç®—æ”¶ç›Šç‡ (%)"""
    try:
        pnl = float(pnl)
        if margin_size and float(margin_size) > 0:
            return round((pnl / float(margin_size)), 4)
        
        # å¦åˆ™å°è¯•æ¨ç®—ä¿è¯é‡‘
        if open_avg and total and leverage:
             margin = (float(open_avg) * float(total)) / int(leverage)
             if margin > 0:
                 return round((pnl / margin), 4)
        return 0.0
    except:
        return 0.0


def format_duration(start_ms, end_ms):
    """è®¡ç®—æŒä»“æ—¶é•¿ï¼Œè¿”å›äººæ€§åŒ–å­—ç¬¦ä¸²"""
    try:
        if not end_ms or not start_ms: return ""
        diff_ms = int(end_ms) - int(start_ms)
        if diff_ms < 0: return "0s"
        
        seconds = int(diff_ms / 1000)
        if seconds < 60:
            return f"{seconds}s"
        elif seconds < 3600:
            return f"{seconds // 60}m {seconds % 60}s"
        elif seconds < 86400:
            return f"{seconds // 3600}h {(seconds % 3600) // 60}m"
        else:
            return f"{seconds // 86400}d {(seconds % 86400) // 3600}h"
    except:
        return ""


def sync_tasks():
    state = load_state()
    synced_ids = set(state.get("synced_ids", []))
    
    # æ™ºèƒ½ç¼“å­˜ï¼šä¸ä»…å­˜ Record IDï¼Œè¿˜å­˜å…³é”®çŠ¶æ€ (Entry Price, Leverage)
    # ç”¨äºæœ¬åœ°å¯¹æ¯”ï¼Œå†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨ API æ›´æ–°
    # ç»“æ„: {"unique_id": {"record_id": "xxx", "entry_price": 1.23, "leverage": 20}}
    feishu_cache = state.get("feishu_cache", {})
    
    # å·²å®Œç»“ ID é›†åˆ (é˜²æ­¢é‡å¤æ›´æ–°å†å²)
    finalized_ids = set(state.get("finalized_ids", []))
    
    print(f"\n[{datetime.now().strftime('%H:%M:%S')}] å¼€å§‹åŒæ­¥ (é—´éš”: {POLL_INTERVAL}s)...")
    
    # ==========================
    # 1. åŒæ­¥å½“å‰æŒä»“ (Open Positions)
    # ==========================
    try:
        open_positions = bitget_client.get_positions()
    except Exception as e:
        print(f"[Bitget] è·å–æŒä»“å¤±è´¥: {e}")
        open_positions = []
        
    print(f"[Core] å½“å‰æŒä»“: {len(open_positions)} ä¸ª")
    
    current_holding_ids = set()

    for pos in open_positions:
        unique_id = get_unique_id(pos)
        current_holding_ids.add(unique_id)
        
        # æå–å…³é”®æ•°æ®
        c_time_ms = int(pos.get("cTime") or 0)
        # å…¼å®¹ä¸åŒæ¥å£çš„å­—æ®µå
        entry_price = float(pos.get("openPriceAvg") or pos.get("openAvgPrice") or 0)
        leverage = int(pos.get("leverage", 0))
        
        # æµ®åŠ¨ç›ˆäº (å³ä¾¿æˆ‘ä»¬å¹³æ—¶ä¸æ›´æ–°å®ƒï¼Œä½†å¦‚æœè§¦å‘æ›´æ–°æ—¶è¿˜æ˜¯éœ€è¦å¸¦ä¸Šæœ€æ–°çš„)
        margin_size = float(pos.get("marginSize", 0))
        unrealized_pnl = float(pos.get("unrealizedPL", 0))
        roe = float(pos.get("roe", 0))
        if roe == 0 and margin_size > 0:
             roe = round((unrealized_pnl / margin_size), 4)

        fields = {
            "å¼€ä»“æ—¶é—´": c_time_ms, 
            "å¸ç§": pos.get("symbol", ""),
            "æ–¹å‘": "å¤š" if pos.get("holdSide") == "long" else "ç©º",
            "æ æ†": leverage,
            "å…¥åœºä»·": entry_price,
            "å‡ºåœºä»·": 0, # æŒä»“ä¸­
            "æ”¶ç›Šé¢": unrealized_pnl, 
            "æ”¶ç›Šç‡": roe,
            "çŠ¶æ€": "æŒä»“ä¸­",
            "positionId": unique_id,
            "å¹³ä»“æ—¶é—´": None,
            "æŒä»“æ—¶é—´": format_duration(c_time_ms, int(time.time() * 1000)) + " (ing)"
        }
        
        # === æ ¸å¿ƒä¼˜åŒ–é€»è¾‘ ===
        cached_data = feishu_cache.get(unique_id)
        
        if not cached_data:
            # Case 1: å…¨æ–°æŒä»“ -> å¿…é¡»åˆ›å»º
            print(f"  -> ğŸŸ¢ æ–°å¢æŒä»“: {fields['å¸ç§']} (API Call)")
            # å…ˆå°è¯•æ‰¾ä¸€ä¸‹ä¸‡ä¸€å·²æœ‰è®°å½• (é˜²æ­¢ state ä¸¢å¤±å¯¼è‡´é‡å¤åˆ›å»º)
            existing_id = feishu_client.find_record(unique_id)
            if existing_id:
                record_id = existing_id
                print(f"     (å‘ç°å·²å­˜åœ¨è®°å½•: {record_id})")
                feishu_client.update_record(record_id, fields)
            else:
                record_id = feishu_client.create_record(fields)
            
            if record_id:
                feishu_cache[unique_id] = {
                    "record_id": record_id,
                    "entry_price": entry_price,
                    "leverage": leverage
                }
                synced_ids.add(unique_id)

        else:
            # Case 2: å·²å­˜åœ¨çš„æŒä»“ -> æ£€æŸ¥æ˜¯å¦å‘ç”Ÿ"ç»“æ„æ€§å˜æ›´" (DCA)
            last_entry_price = cached_data.get("entry_price", 0)
            last_leverage = cached_data.get("leverage", 0)
            record_id = cached_data.get("record_id")
            
            # åˆ¤æ–­æ˜¯å¦æœ‰å…³é”®å˜åŒ– (ä»·æ ¼å˜åŠ¨è¶…è¿‡ 0.0001% è§†ä¸ºè¡¥ä»“/å‡ä»“; æ æ†å˜åŒ–)
            # æµ®åŠ¨ç›ˆäºçš„å˜åŒ–è¢«å¿½ç•¥ï¼Œä¸è§¦å‘ API è°ƒç”¨
            is_dca_event = abs(entry_price - last_entry_price) > (entry_price * 0.000001) or leverage != last_leverage
            
            if is_dca_event:
                print(f"  -> ğŸŸ¡ ä»“ä½å˜åŠ¨(è¡¥ä»“/è°ƒæ æ†): {fields['å¸ç§']} (API Call)")
                success = feishu_client.update_record(record_id, fields)
                if success:
                    # æ›´æ–°ç¼“å­˜
                    feishu_cache[unique_id]["entry_price"] = entry_price
                    feishu_cache[unique_id]["leverage"] = leverage
            else:
                # Case 3: åªæœ‰æµ®åŠ¨ç›ˆäºå˜åŒ– -> è·³è¿‡æ›´æ–° (çœé’±!)
                # print(f"  -> âšªï¸ å¿½ç•¥æµ®åŠ¨ç›ˆäº: {fields['å¸ç§']} (Cached)")
                pass

    # ä¿å­˜ç¼“å­˜çŠ¶æ€
    state["feishu_cache"] = feishu_cache
    state["synced_ids"] = list(synced_ids)
    save_state(state)

    # ==========================
    # 2. åŒæ­¥å†å²ä»“ä½ (History Positions)
    # ==========================
    try:
        history_list = bitget_client.get_history_positions()
    except Exception as e:
        print(f"[Bitget] è·å–å†å²å¤±è´¥: {e}")
        history_list = []
        
    print(f"[Core] å†å²è®°å½•: {len(history_list)} æ¡ (æœ€è¿‘)")
    history_list.reverse()
    
    for pos in history_list:
        unique_id = get_unique_id(pos)
        
        # å¦‚æœå·²ç»æ ‡è®°ä¸º"å®Œç»“"ï¼Œç›´æ¥è·³è¿‡ (ç»å¯¹é›¶æ¶ˆè€—)
        if unique_id in finalized_ids:
            continue
            
        # å‡†å¤‡æ•°æ®
        c_time_ms = int(pos.get("ctime") or pos.get("cTime") or 0)
        u_time_ms = int(pos.get("utime") or pos.get("uTime") or 0)
        net_profit = float(pos.get("netProfit", 0))
        pnl = float(pos.get("pnl", 0))
        final_profit = net_profit if net_profit != 0 else pnl
        
        # å°è¯•ä»ç¼“å­˜è·å–ä¹‹å‰çš„ marginSize æ¥è®¡ç®—ç²¾ç¡® ROE
        cached_data = feishu_cache.get(unique_id, {})
        # æ³¨æ„: è¿™é‡Œçš„ openAvg å¯èƒ½æ˜¯è¡¥ä»“åçš„å‡ä»·ï¼Œè¿™æ˜¯æˆ‘ä»¬æƒ³è¦çš„
        open_avg = float(pos.get("openAvgPrice", 0))
        total_vol = float(pos.get("openTotalPos", 0)) # æ€»æˆäº¤é‡
        leverage = int(pos.get("leverage", 0))
        
        # è‡ªåŠ¨è®¡ç®— ROE (å‡€æ”¶ç›Š / ä¿è¯é‡‘)
        # ä¿è¯é‡‘ = (å‡ä»· * æ•°é‡) / æ æ†
        cal_margin = 0
        if leverage > 0 and total_vol > 0:
            cal_margin = (open_avg * total_vol) / leverage
            
        roe = 0
        if cal_margin > 0:
            roe = round(final_profit / cal_margin, 4)
        
        fields = {
            "å¼€ä»“æ—¶é—´": c_time_ms,
            "å¸ç§": pos.get("symbol", ""),
            "æ–¹å‘": "å¤š" if pos.get("holdSide") == "long" else "ç©º",
            "å…¥åœºä»·": open_avg,
            "å‡ºåœºä»·": float(pos.get("closeAvgPrice", 0)),
            "æ”¶ç›Šé¢": final_profit,
            "æ”¶ç›Šç‡": roe, # ä½¿ç”¨ä¸€å®šè¦é‡æ–°è®¡ç®—çš„ ROE
            "çŠ¶æ€": "ç›ˆåˆ©" if final_profit > 0 else "äºæŸ",
            "positionId": unique_id,
            "å¹³ä»“æ—¶é—´": u_time_ms,
            "æŒä»“æ—¶é—´": format_duration(c_time_ms, u_time_ms)
        }
        if leverage > 0:
            fields["æ æ†"] = leverage

        # æŸ¥æ‰¾ Record ID (ä¼˜å…ˆæœ¬åœ°ç¼“å­˜)
        record_id = cached_data.get("record_id")
        
        if not record_id:
            # ç¼“å­˜é‡Œæ²¡æœ‰ï¼Œè¯´æ˜å¯èƒ½æ˜¯ç³»ç»Ÿè¿˜æ²¡è·‘æ—¶å¼€çš„å•ï¼Œå»é£ä¹¦æŸ¥ä¸€æ¬¡
            record_id = feishu_client.find_record(unique_id)
        
        if record_id:
            log_info(f"  -> ğŸ”µ è®¢å•å®Œç»“: {fields['å¸ç§']} (API Call)")
            success = feishu_client.update_record(record_id, fields)
            if success:
                finalized_ids.add(unique_id)
                # å®Œç»“åå¯ä»¥æ¸…é™¤ cache é‡Œçš„è¿‡ç¨‹æ•°æ®ï¼Œä½†ä¸ºäº† ID æ˜ å°„å»ºè®®ä¿ç•™
        else:
            log_info(f"  -> ğŸŸ£ è¡¥å½•å†å²: {fields['å¸ç§']} (API Call)")
            new_id = feishu_client.create_record(fields)
            if new_id:
                synced_ids.add(unique_id)
                finalized_ids.add(unique_id)

    # ä¿å­˜æœ€ç»ˆçŠ¶æ€
    state["feishu_cache"] = feishu_cache
    state["finalized_ids"] = list(finalized_ids)
    state["synced_ids"] = list(synced_ids)
    state["last_sync_time"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    save_state(state)


if __name__ == "__main__":
    log_info(f"å¯åŠ¨æ™ºèƒ½åŒæ­¥æ¨¡å¼ (API èŠ‚çº¦ç‰ˆ)")
    log_info(f"è½®è¯¢é—´éš”: {POLL_INTERVAL} ç§’")
    while True:
        try:
            sync_tasks()
            log_info(f"ç­‰å¾… {POLL_INTERVAL} ç§’...")
            time.sleep(POLL_INTERVAL)
        except KeyboardInterrupt:
            log_info("ç¨‹åºåœæ­¢")
            break
        except Exception as e:
            log_error(f"ä¸»å¾ªç¯å¼‚å¸¸: {e}")
            time.sleep(POLL_INTERVAL) # å‡ºé”™ä¹Ÿç­‰å¾…åŒæ ·æ—¶é—´
